\chapter{Stato dell'arte}
\label{capitolo2}
\thispagestyle{empty}

\begin{quotation}
{\footnotesize
\noindent{\emph{Doc: Ecco perché non ha funzionato: c'è scritto ``Made in Japan''. \\
Marty: E che vuol dire Doc? Tutta la roba migliore è fatta in Giappone. \\
Doc: Incredibile!
} }
\begin{flushright}
Ritorno al Futuro, parte III
\end{flushright}
}
\end{quotation}
\vspace{0.5cm}

\section{SLAM}

Il problema della localizzazione di un robot in un ambiete sconosciuto è stato affrontato fin dagli anni 90' a partire da \cite{174711}, articolo nel quale per la prima volta si delineava un framework per localizzare un robot costruendo contemporaneamente la mappa dell'ambiente.
Tramite l'utilizzo di sonar, venivano estratte feature geometriche con cui veniva costruita la mappa, nella quale il robot si localizzava. 
Il problema principale della localizzazione è il ``problema della correlazione'': se la posizione della feature rispetto alla quale ci si localizza è affetta da incertezza, la conseguente stima della posizione effettuata rispetto a tale feature sarà affetta da un errore che dipende dall'errore della posizione della feature stessa. 
Questo problema diventa tanto più grave se si pensa che la posizione del robot in ogni istante non è nota a priori, ma deve essere stimata sulla base delle osservazioni precedenti. 
Come è facile vedere, è necessario risolvere questo problema per evitare che l'errore della generazione della mappa e l'errore della stima della posizione divergano nel tempo. 
Per risolvere questo problema, gli autori hanno utilizzato un filtro di Kalman esteso.

Come è noto, il filtro di Kalman è uno stimatore Bayesiano ricorsivo, che, supposto noto il modello lineare che regola la generazione dei dati e la loro osservazione, supposto che l'errore di misura e di modello siano gaussiani, restituisce la densità di probabilità del sistema osservato. 
Il filtro di Kalman, se utilizzato secondo le ipotesi, è uno stimatore ottimo dello stato del sistema osservato, secondo i minimi quadrati.
Tuttavia, nell'ambito della robotica, e in particolare nel problema della localizzazione, il modello di generazione e osservazione dei dati non può essere considerato lineare.
E' quindi necessario utilizzare un'estensione del filtro di kalman al caso non lineare: il filtro di Kalman esteso (EKF) è una delle possibili soluzioni al problema. 
L'idea alla base del filtro di Kalmen esteso è quella di lavorare sul modello linearizzato, stimato ricorsivamente dal modello non lineare sulla base della stima corrente.

Per avere una buona stima della posizione è necessario utilizzare un gran numero di feature, numero che cresce molto rapidamente con l'aumentare della dimensione dell'ambiente.
La complessità computazionale dell'approccio tradizionale basato sul filtro di Kalman esteso è $\mathcal{O}(N^3)$, con $N$ numero di feature, e quindi il tempo di calcolo diventa ben presto inaccettabile.
Per risolvere questo problema è stato introdotto in \cite{Montemerlo02a}  un nuovo algoritmo detto FastSLAM, che consiste nell'utilizzo del Particle Filter, e del filtro di Kalman esteso in combinazione. L'algoritmo associa ad ogni feature considerata, un filtro di Kalman esteso.
Il Particle Filter è un altro stimatore bayesiano ricorsivo, che, invece di un modello e dell'assunzione di rumore gaussiano, sfrutta metodi di tipo monte carlo per stimare la densità di probabilità del sistema che genera i dati.
la densità di probabilità congiunta, invece, viene calcolata sfruttando il Particle filter. 
Il risultato è un algoritmo che ha complessità computazionale $\mathcal{O}(N\log M)$, con $M$ numero di feature e $N$ è il numero di particelle usate dal Particle Filter. 
Questo approccio rende il problema trattabile nella maggior parte dei casi, pur essendo pesante computazionalmente, essendo necessario un elevato numero di particelle per avere una buona localizzazione.

Vista la particolarità del problema quando il sensore utilizzato è una videocamera monoculare, sono stati sviluppati algoritmi ad hoc.
Uno degli algoritmi più usati è PTAM, descritto in \cite{klein07parallel} e \cite{klein08improving}.
L'idea alla base di questo algoritmo è dividere in due thread separati il tracking e la creazione della mappa: un thread si occupa del tracking robusto di features a basso livello, mentre l'altro thread si occupa della creazione della mappa. 
Per rendere efficente il processo di mapping, solo i keyframe, ossia i frame che contengono maggiore informazione rispetto a quella già presente, vengono considerati.
Per rendere il processo di mapping robusto, vengono utilizzate tecniche batch per costruire la mappa, come ad esempio il bundle adjustment.
PTAM, tuttavia, nasce per applicazioni di realtà aumentata, e quindi necessita di una inizializzazione, per risolvere i problemi del'acquisizione del primo keyframe e per gestire la scala della mappa.

Un altro approccio alternativo è quello di usare tutti i dati dell'immagine per eseguire la localizzazzione, questo approccio è alla base ad esempio di DTAM, Dense Tracking and Mapping, descritto in \cite{conf/iccv/NewcombeLD11}.

Si sono dimostrati efficaci anche i metodi semi-diretti, come SVO, Semi Direct Visual Odometry, un algoritmo che riesce a ottenere altissime prestazioni limitando l'estrazione delle features ad alto livello ai soli keyframe, operando direttamente sulle intensità dei pixel nei frame successivi, eliminando le fasi computazionalmente più onerose, che sono l'estrazione e l'abbinamento delle feature. SVO si basa sulle idee di PTAM, ma migliora sia le prestazioni, riuscendo a essere computazionalmente più legegro, sia la precisione della mappa e della localizzazione riducendo di molto gli outlier.

\section{Riconoscimento di Oggetti}

\cite{Viola01rapidobject} \cite{Lienhart02anextended}

\section{Reasoning}
